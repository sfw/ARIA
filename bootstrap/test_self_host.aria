# Self-Hosting Test for ARIA Bootstrap Compiler
# Tests that the bootstrap compiler can process its own source files

# ============================================================================
# Simple Tokenizer for Self-Hosting Test
# ============================================================================

# Token kinds (minimal set for testing)
f TK_F() -> Int = 1
f TK_S() -> Int = 2
f TK_IDENT() -> Int = 100
f TK_INT() -> Int = 101
f TK_STRING() -> Int = 102
f TK_NEWLINE() -> Int = 103
f TK_COMMENT() -> Int = 104
f TK_OTHER() -> Int = 199
f TK_EOF() -> Int = 200

s Token
    kind: Int
    lexeme: Str

# ============================================================================
# Character Classification
# ============================================================================

f is_alpha(c: Char) -> Bool
    (c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z') || c == '_'

f is_digit(c: Char) -> Bool
    c >= '0' && c <= '9'

f is_alnum(c: Char) -> Bool
    is_alpha(c) || is_digit(c)

f is_whitespace(c: Char) -> Bool
    c == ' ' || c == '\t' || c == '\r'

# ============================================================================
# Simple Scanner
# ============================================================================

s Scanner
    source: Str
    pos: Int
    tokens: [Token]
    stats: ScanStats

s ScanStats
    functions: Int
    structs: Int
    identifiers: Int
    numbers: Int
    strings: Int
    comments: Int
    lines: Int

f stats_new() -> ScanStats
    ScanStats { functions: 0, structs: 0, identifiers: 0, numbers: 0, strings: 0, comments: 0, lines: 1 }

f scanner_new(source: Str) -> Scanner
    Scanner { source: source, pos: 0, tokens: [], stats: stats_new() }

f at_end(s: Scanner) -> Bool
    s.pos >= str_len(s.source)

f peek(s: Scanner) -> Option[Char]
    if at_end(s) then None else str_char_at(s.source, s.pos)

f advance(s: Scanner) -> Scanner
    Scanner { source: s.source, pos: s.pos + 1, tokens: s.tokens, stats: s.stats }

f skip_whitespace(s: Scanner) -> Scanner
    m peek(s)
        Some(c) ->
            if is_whitespace(c) then skip_whitespace(advance(s)) else s
        None -> s

f scan_identifier(s: Scanner, start: Int) -> Scanner
    m peek(s)
        Some(c) ->
            if is_alnum(c)
                scan_identifier(advance(s), start)
            else
                finish_identifier(s, start)
        None -> finish_identifier(s, start)

f finish_identifier(s: Scanner, start: Int) -> Scanner
    lexeme := str_slice(s.source, start, s.pos)
    kind := classify_keyword(lexeme)
    tok := Token { kind: kind, lexeme: lexeme }
    new_tokens := vec_push(s.tokens, tok)
    new_stats := update_stats_ident(s.stats, kind)
    Scanner { source: s.source, pos: s.pos, tokens: new_tokens, stats: new_stats }

f classify_keyword(lexeme: Str) -> Int
    if lexeme == "f" then TK_F()
    else if lexeme == "s" then TK_S()
    else TK_IDENT()

f update_stats_ident(st: ScanStats, kind: Int) -> ScanStats
    if kind == TK_F()
        ScanStats { functions: st.functions + 1, structs: st.structs, identifiers: st.identifiers, numbers: st.numbers, strings: st.strings, comments: st.comments, lines: st.lines }
    else if kind == TK_S()
        ScanStats { functions: st.functions, structs: st.structs + 1, identifiers: st.identifiers, numbers: st.numbers, strings: st.strings, comments: st.comments, lines: st.lines }
    else
        ScanStats { functions: st.functions, structs: st.structs, identifiers: st.identifiers + 1, numbers: st.numbers, strings: st.strings, comments: st.comments, lines: st.lines }

f scan_number(s: Scanner, start: Int) -> Scanner
    m peek(s)
        Some(c) ->
            if is_digit(c)
                scan_number(advance(s), start)
            else
                finish_number(s, start)
        None -> finish_number(s, start)

f finish_number(s: Scanner, start: Int) -> Scanner
    lexeme := str_slice(s.source, start, s.pos)
    tok := Token { kind: TK_INT(), lexeme: lexeme }
    new_tokens := vec_push(s.tokens, tok)
    new_stats := ScanStats { functions: s.stats.functions, structs: s.stats.structs, identifiers: s.stats.identifiers, numbers: s.stats.numbers + 1, strings: s.stats.strings, comments: s.stats.comments, lines: s.stats.lines }
    Scanner { source: s.source, pos: s.pos, tokens: new_tokens, stats: new_stats }

f scan_string(s: Scanner) -> Scanner
    scan_string_loop(advance(s), s.pos)

f scan_string_loop(s: Scanner, start: Int) -> Scanner
    m peek(s)
        Some(c) ->
            if c == '"'
                finish_string(advance(s), start)
            else
                scan_string_loop(advance(s), start)
        None -> s

f finish_string(s: Scanner, start: Int) -> Scanner
    lexeme := str_slice(s.source, start, s.pos)
    tok := Token { kind: TK_STRING(), lexeme: lexeme }
    new_tokens := vec_push(s.tokens, tok)
    new_stats := ScanStats { functions: s.stats.functions, structs: s.stats.structs, identifiers: s.stats.identifiers, numbers: s.stats.numbers, strings: s.stats.strings + 1, comments: s.stats.comments, lines: s.stats.lines }
    Scanner { source: s.source, pos: s.pos, tokens: new_tokens, stats: new_stats }

f scan_comment(s: Scanner) -> Scanner
    scan_comment_loop(advance(s))

f scan_comment_loop(s: Scanner) -> Scanner
    m peek(s)
        Some(c) ->
            if c == '\n'
                s
            else
                scan_comment_loop(advance(s))
        None -> s

f update_stats_comment(st: ScanStats) -> ScanStats
    ScanStats { functions: st.functions, structs: st.structs, identifiers: st.identifiers, numbers: st.numbers, strings: st.strings, comments: st.comments + 1, lines: st.lines }

f update_stats_newline(st: ScanStats) -> ScanStats
    ScanStats { functions: st.functions, structs: st.structs, identifiers: st.identifiers, numbers: st.numbers, strings: st.strings, comments: st.comments, lines: st.lines + 1 }

# Main scan loop
f scan_all(source: Str) -> ScanStats
    s := scanner_new(source)
    s2 := scan_loop(s)
    s2.stats

f scan_loop(s: Scanner) -> Scanner
    if at_end(s)
        s
    else
        s2 := skip_whitespace(s)
        if at_end(s2)
            s2
        else
            scan_token(s2)

f scan_token(s: Scanner) -> Scanner
    m peek(s)
        Some(c) ->
            if c == '\n'
                new_stats := update_stats_newline(s.stats)
                scan_loop(Scanner { source: s.source, pos: s.pos + 1, tokens: s.tokens, stats: new_stats })
            else if c == '#'
                s2 := scan_comment(s)
                new_stats := update_stats_comment(s2.stats)
                scan_loop(Scanner { source: s2.source, pos: s2.pos, tokens: s2.tokens, stats: new_stats })
            else if c == '"'
                s2 := scan_string(s)
                scan_loop(s2)
            else if is_alpha(c)
                s2 := scan_identifier(advance(s), s.pos)
                scan_loop(s2)
            else if is_digit(c)
                s2 := scan_number(advance(s), s.pos)
                scan_loop(s2)
            else
                scan_loop(advance(s))
        None -> s

# ============================================================================
# Self-Compilation Tests
# ============================================================================

f test_scan_file(path: Str) -> Bool
    print("Scanning:")
    print(path)
    m file_read(path)
        Ok(content) ->
            len := str_len(content)
            print("  File length:")
            print(len)
            # Scan first 1000 chars to avoid stack overflow
            sample_len := if len > 1000 then 1000 else len
            sample := str_slice(content, 0, sample_len)
            stats := scan_all(sample)
            print("  Sample lines:")
            print(stats.lines)
            print("  Sample functions:")
            print(stats.functions)
            print("  Sample structs:")
            print(stats.structs)
            print("  OK")
            true
        Err(e) ->
            print("  ERROR: Could not read file")
            false

f test_scan_aria_code() -> Bool
    print("Scanning ARIA code sample:")
    # Simple single-line sample that includes functions and struct keywords
    sample := "f foo() -> Int = 42\nf bar(x: Int) -> Int = x\ns Point\n    x: Int\nf main() -> Int = 0\n"
    stats := scan_all(sample)
    print("  Lines:")
    print(stats.lines)
    print("  Functions:")
    print(stats.functions)
    print("  Structs:")
    print(stats.structs)
    print("  Identifiers:")
    print(stats.identifiers)
    # Expect 3 functions (f foo, f bar, f main) and 1 struct (s Point)
    ok := stats.functions == 3 && stats.structs == 1
    if ok then print("  PASS") else print("  FAIL")
    ok

f run_self_host_tests() -> Int
    print("=== Self-Hosting Tests ===")
    print("")

    # Test scanning ARIA code sample
    t0 := test_scan_aria_code()
    print("")

    # Test reading and scanning bootstrap source files
    t1 := test_scan_file("bootstrap/token.aria")
    print("")

    t2 := test_scan_file("bootstrap/mir.aria")
    print("")

    t3 := test_scan_file("bootstrap/aria_bootstrap.aria")
    print("")

    all_passed := t0 && t1 && t2 && t3

    if all_passed
        print("All self-hosting tests passed!")
        print("The bootstrap compiler can process its own source files.")
        0
    else
        print("Some self-hosting tests failed")
        1

f main() -> Int = run_self_host_tests()
