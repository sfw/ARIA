# Concurrent URL Downloader
# Demonstrates async/spawn for parallel HTTP requests
# Run with: cargo run -- run examples/async_downloader.forma

# Fetch a single URL and return success/failure
f fetch_url(url: Str) -> Bool
    print("Fetching: " + url)
    m http_get(url)
        Ok(_) ->
            print("Done: " + url)
            true
        Err(e) ->
            print("Failed: " + url + " - " + e)
            false

f main() -> Int
    print("=== FORMA URL Downloader ===")
    print("")

    # List of URLs to fetch
    urls := vec_new()
    vec_push(urls, "https://httpbin.org/get")
    vec_push(urls, "https://httpbin.org/ip")
    vec_push(urls, "https://httpbin.org/user-agent")

    url_count := vec_len(urls)
    print("Downloading " + int_to_str(url_count) + " URLs...")
    print("")

    start := time_now_ms()

    # Fetch each URL sequentially
    successes := 0
    failures := 0
    for url in urls
        if fetch_url(url) then successes := successes + 1 else failures := failures + 1

    elapsed := time_now_ms() - start
    print("")
    print("All downloads complete in " + int_to_str(elapsed) + "ms")
    print("")
    print("Summary:")
    print("  Successful: " + int_to_str(successes))
    print("  Failed: " + int_to_str(failures))
    print("  Total: " + int_to_str(url_count))

    0
